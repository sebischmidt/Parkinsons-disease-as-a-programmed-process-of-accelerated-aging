{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51a6dbd-dea6-498c-a661-39a7c2b5a3ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "859c3f27-25bd-47dd-bde4-2f36dbc6dbfa",
   "metadata": {},
   "source": [
    "# Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cdcc9d6-ccb3-4434-9719-d4b5496eb692",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "os.chdir('/root/host_home')\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "# import matplotlib.colors as mcolors # Not directly used\n",
    "import random # For mock pathway file creation\n",
    "\n",
    "# gseapy and decoupler imports\n",
    "import gseapy as gs\n",
    "import decoupler as dc\n",
    "from gprofiler import GProfiler\n",
    "from scipy.stats import hypergeom\n",
    "from statsmodels.stats.multitest import multipletests # For decoupler and integration\n",
    "\n",
    "\n",
    "# networkx import for network plots\n",
    "import networkx as nx\n",
    "\n",
    "# adjustText import (optional, for Manhattan plots)\n",
    "try:\n",
    "    from adjustText import adjust_text\n",
    "    ADJUST_TEXT_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"Warning: adjustText library not found. Labels on Manhattan plots might overlap.\")\n",
    "    ADJUST_TEXT_AVAILABLE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d25d09-dbf4-42c2-a5cc-14a32ff486e1",
   "metadata": {},
   "source": [
    "# Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4dc15083-ec47-4730-9284-67ef91d1108a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Variables\n",
    "save_dir = 'hp_NPCs/SCENIC/'\n",
    "DEG_dir = 'hp_NPCs/tables/diffxpy/' \n",
    "output_dir = os.path.join(save_dir, 'enrichment_analysis/')\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "cell_types = ['NSC1a', 'NSC1b', 'NSC2a', 'NSC2b', 'Apop.-NSC', 'NCSC', 'Apop.-NCSC', 'Glial-precursors', 'Immature-neurons', 'bulk_like']\n",
    "DEG_SYMBOL_COL = 'gene_symbols' \n",
    "\n",
    "PATHWAY_FILES = {\n",
    "    'GO_BP': os.path.join(DEG_dir, 'cell_types_DEGs_diffxpy_pathways_GO_terms.xlsx'),\n",
    "    'KEGG': os.path.join(DEG_dir, 'cell_types_DEGs_diffxpy_pathways_KEGG_terms.xlsx'),\n",
    "    'WP': os.path.join(DEG_dir, 'cell_types_DEGs_diffxpy_pathways_WP_terms.xlsx'),\n",
    "    'Reactome': os.path.join(DEG_dir, 'cell_types_DEGs_diffxpy_pathways_Reactome_terms.xlsx'),\n",
    "    'mKEGG': os.path.join(DEG_dir, 'cell_types_DEGs_diffxpy_pathways_mKEGG_terms.xlsx'),\n",
    "}\n",
    "PATHWAY_ID_COL = 'ID' \n",
    "PATHWAY_NAME_COL = 'Description' \n",
    "PATHWAY_PADJ_COL = 'qvalue' \n",
    "PATHWAY_GENES_COL = 'geneID' \n",
    "\n",
    "SIGNIFICANCE_CUTOFF = 0.05 \n",
    "LABEL_QVAL_THRESHOLD = 0.01 \n",
    "TOP_N_LABEL = 20 \n",
    "TOP_N_PIE = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4701a2e-3538-42c6-83cb-2e652b3b78ee",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d37d6aa-9ef0-436f-a5ab-58f82d299314",
   "metadata": {},
   "source": [
    "## Enrichment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ec21eab-da5c-4270-884b-39cc2f1615fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- TF ENRICHMENT FUNCTIONS ---\n",
    "\n",
    "def run_gseapy_enrichment(deg_list, cell_type, tf_libs, organism='Human', sig_cutoff=0.05):\n",
    "    \"\"\"Runs gseapy enrichment using Enrichr libraries.\"\"\"\n",
    "    global output_dir\n",
    "    method_name = \"gseapy\"\n",
    "\n",
    "    # --- Create directory structure ---\n",
    "    table_dir = os.path.join(output_dir, method_name, \"tables\")\n",
    "    figure_dir = os.path.join(output_dir, method_name, \"figures\")\n",
    "    os.makedirs(table_dir, exist_ok=True)\n",
    "    os.makedirs(figure_dir, exist_ok=True)\n",
    "    \n",
    "    if not deg_list:\n",
    "        print(f\"Warning: Empty DEG list for {cell_type}. Skipping gseapy.\")\n",
    "        return pd.DataFrame(columns=['Term', 'Genes', 'Adjusted P-value'])\n",
    "    \n",
    "    print(f\"Running gseapy for {cell_type} with {len(deg_list)} genes. Sources: {tf_libs}.\")\n",
    "    try:\n",
    "        enr_results_obj = gs.enrichr(\n",
    "            gene_list=deg_list, gene_sets=tf_libs, organism=organism,\n",
    "            outdir=None, cutoff=sig_cutoff, no_plot=True\n",
    "        )\n",
    "        enr_df = enr_results_obj.results\n",
    "        enr_df = enr_df[~enr_df['Term'].str.contains('mouse|Mouse', case=False, na=False)]\n",
    "        sig_df = enr_df[enr_df['Adjusted P-value'] < sig_cutoff].sort_values('Adjusted P-value')\n",
    "\n",
    "        if not sig_df.empty:\n",
    "            sig_df.to_csv(os.path.join(table_dir, f\"{method_name}_{cell_type}_sig_tf.csv\"), index=False)\n",
    "            print(f\"  Gseapy analysis for {cell_type} complete. {len(sig_df)} terms found.\")\n",
    "            return sig_df[['Term', 'Genes', 'Adjusted P-value']].copy()\n",
    "        else:\n",
    "            print(f\"  Gseapy returned no enrichment results for {cell_type} with sources {tf_libs}.\")\n",
    "            return pd.DataFrame(columns=['Term', 'Genes', 'Adjusted P-value'])\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  Error during gseapy for {cell_type}: {e}\")\n",
    "        return pd.DataFrame(columns=['Term', 'Genes', 'Adjusted P-value'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db530afa-cb73-45e9-ac4f-206ddef9aafe",
   "metadata": {},
   "source": [
    "## TF-Pathway interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "507319d3-337e-4a9a-97dd-441b14c570e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- PATHWAY ENRICHMENT LOADING ---\n",
    "def load_pathways(cell_type, pathway_db_key='GO_BP'):\n",
    "    \"\"\"Loads pre-computed pathway enrichment results for one DB type.\"\"\"\n",
    "    global PATHWAY_FILES, PATHWAY_PADJ_COL, PATHWAY_GENES_COL, PATHWAY_NAME_COL, PATHWAY_ID_COL, SIGNIFICANCE_CUTOFF, output_dir\n",
    "    empty_df = pd.DataFrame(columns=['Term', 'Description', 'Genes', 'Adjusted P-value', 'Database'])\n",
    "\n",
    "    if pathway_db_key not in PATHWAY_FILES: return empty_df\n",
    "    fpath = PATHWAY_FILES[pathway_db_key]\n",
    "\n",
    "    try:\n",
    "        sheet = cell_type \n",
    "        try: df = pd.read_excel(fpath, sheet_name=sheet)\n",
    "        except ValueError: \n",
    "             print(f\"  Sheet '{sheet}' not found in {fpath}.\")\n",
    "             return empty_df \n",
    "        \n",
    "\n",
    "        req_cols = [PATHWAY_PADJ_COL, PATHWAY_GENES_COL, PATHWAY_NAME_COL, PATHWAY_ID_COL]\n",
    "        if not all(c in df.columns for c in req_cols): print(f\"  Error: Missing cols in {fpath}\"); return empty_df\n",
    "\n",
    "        sig_df = df[df[PATHWAY_PADJ_COL] < SIGNIFICANCE_CUTOFF].copy()\n",
    "        if sig_df.empty: print(f\"  No significant pathways for {pathway_db_key} in {cell_type}.\"); return empty_df\n",
    "\n",
    "        sig_df['Database'] = pathway_db_key\n",
    "        rn_df = sig_df.rename(columns={PATHWAY_ID_COL:'Term', PATHWAY_NAME_COL:'Description', \n",
    "                                       PATHWAY_GENES_COL:'Genes_temp', PATHWAY_PADJ_COL:'Adjusted P-value'})\n",
    "        rn_df['Genes'] = rn_df['Genes_temp'].astype(str).str.replace('/', ';')\n",
    "        final_df = rn_df[['Term','Description','Genes','Adjusted P-value','Database']].copy()\n",
    "        return final_df\n",
    "    except Exception as e: print(f\"  Error loading {pathway_db_key} for {cell_type}: {e}\"); return empty_df\n",
    "\n",
    "\n",
    "# --- TF-PATHWAY INTEGRATION ---\n",
    "def integrate_tf_path(sig_tfs_df, sig_paths_df, cell_type, bg_genes, tf_tool, interaction_qval_cutoff=0.05, overlap_fraction_threshold=0.1):\n",
    "    \"\"\"Integrates TF and Pathway results.\"\"\"\n",
    "    print(f\"--- Integrating TF ({tf_tool}) & Pathways for {cell_type} ---\")\n",
    "    integ_out_dir = os.path.join(output_dir, tf_tool, \"tables\")\n",
    "    os.makedirs(integ_out_dir, exist_ok=True)\n",
    "\n",
    "    if sig_tfs_df.empty or sig_paths_df.empty: print(f\"  Skipping: Empty TFs/Pathways.\"); return pd.DataFrame()\n",
    "    if not bg_genes: print(f\"  Warning: Empty background for integration.\")\n",
    "    \n",
    "    bg_set = set(bg_genes)\n",
    "    links = []\n",
    "    for _,tf_r in sig_tfs_df.iterrows():\n",
    "        tf_n,tf_g_str = tf_r.get('Term','?TF'),str(tf_r.get('Genes',''))\n",
    "        tf_targets = set(tf_g_str.split(';')) if tf_g_str else set()\n",
    "        for _,p_r in sig_paths_df.iterrows():\n",
    "            p_id,p_n,p_db = p_r.get('Term','?PathID'),p_r.get('Description','?PathN'),p_r.get('Database','?DB')\n",
    "            p_g_str = str(p_r.get('Genes','')); p_members = set(p_g_str.split(';')) if p_g_str else set()\n",
    "            shared = tf_targets.intersection(p_members)\n",
    "            k_o = len(shared)\n",
    "            if k_o > 0 and bg_set:\n",
    "                tf_t_bg,p_m_bg = tf_targets.intersection(bg_set),p_members.intersection(bg_set)\n",
    "                sh_bg = shared.intersection(bg_set); k_o_bg = len(sh_bg)\n",
    "                M,n_tf,N_p = len(bg_set),len(tf_t_bg),len(p_m_bg)\n",
    "                if n_tf > 0 and N_p > 0 and k_o_bg > 0:\n",
    "                    #M = total number of genes in the background\n",
    "                    #n = number of TF-related genes\n",
    "                    #N = number of pathway-related genes\n",
    "                    #k = observed overlap between pathway and TF genes                                        \n",
    "                    \n",
    "                    pval = hypergeom.sf(k_o_bg-1,M,n_tf,N_p)\n",
    "                    overlap_frac_vs_pathway = k_o_bg / N_p if N_p > 0 else 0\n",
    "                    overlap_frac_vs_tf = k_o_bg / n_tf if n_tf > 0 else 0\n",
    "            \n",
    "                    links.append({'TF_Tool':tf_tool,\n",
    "                                  'TF':tf_n,\n",
    "                                  'Pathway_DB':p_db,\n",
    "                                  'Pathway_ID':p_id,\n",
    "                                  'Pathway_Name':p_n,\n",
    "                                  'TF_Adj_Pval':tf_r.get('Adjusted P-value',np.nan),\n",
    "                                  'Pathway_Adj_Pval':p_r.get('Adjusted P-value',np.nan), \n",
    "                                  'tf_regulon_size': n_tf,\n",
    "                                  'pathway_size': N_p,\n",
    "                                  'overlap_size': k_o_bg,\n",
    "                                  'overlap_frac_vs_pathway': overlap_frac_vs_pathway,\n",
    "                                  'overlap_frac_vs_tf': overlap_frac_vs_tf, # Added this to the output\n",
    "                                  'Shared_Genes':';'.join(sorted(list(sh_bg))),\n",
    "                                  'interaction_Pval':pval})\n",
    "    if not links: print(f\"  No links found for {cell_type} ({tf_tool}).\"); return pd.DataFrame()\n",
    "    links_df = pd.DataFrame(links); links_df.dropna(subset=['interaction_Pval'],inplace=True)\n",
    "    if links_df.empty: return pd.DataFrame()\n",
    "    reject,p_adj,_,_ = multipletests(links_df['interaction_Pval'],method='fdr_bh', alpha=interaction_qval_cutoff)\n",
    "    links_df['interaction_Adj_Pval'] = p_adj; links_df = links_df.sort_values(by='interaction_Adj_Pval')\n",
    "    links_df = links_df[\n",
    "        (links_df['interaction_Adj_Pval'] < interaction_qval_cutoff) &\n",
    "        (\n",
    "            (links_df['overlap_frac_vs_pathway'] > overlap_fraction_threshold) | \n",
    "            (links_df['overlap_frac_vs_tf'] > overlap_fraction_threshold)\n",
    "        )]\n",
    "    links_df.to_csv(os.path.join(integ_out_dir,f\"{tf_tool}_{cell_type}_tf_path_links.csv\"),index=False)\n",
    "    print(f\"  Found {len(links_df)} TF-Pathway links for {cell_type} ({tf_tool}).\")\n",
    "    return links_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116c0932-f21b-4a9f-8ec9-6983b645fe86",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34da6aee-460c-4897-ab07-c5c65085f8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_manhattan(links_df, cell_type, tf_tool, sig_thr=SIGNIFICANCE_CUTOFF, n_lab=TOP_N_LABEL, lab_thr=LABEL_QVAL_THRESHOLD):\n",
    "    \"\"\"Creates Manhattan-style plot for TF-Pathway links, y-axis is interaction_Adj_Pval.\"\"\"\n",
    "    if links_df.empty or 'interaction_Adj_Pval' not in links_df.columns or 'Pathway_DB' not in links_df.columns:\n",
    "        print(f\"  Manhattan: Invalid data for {cell_type} ({tf_tool}). Missing 'interaction_Adj_Pval' or 'Pathway_DB'. Skipping.\"); return\n",
    "    print(f\"--- Plotting Manhattan: {cell_type} ({tf_tool}) ---\")\n",
    "    plot_dir = os.path.join(output_dir, tf_tool, \"figures\")\n",
    "    os.makedirs(plot_dir, exist_ok=True)\n",
    "\n",
    "    df = links_df.copy(); \n",
    "    df['interaction_Adj_Pval'] = pd.to_numeric(df['interaction_Adj_Pval'],errors='coerce')\n",
    "    df.dropna(subset=['interaction_Adj_Pval'],inplace=True)\n",
    "    df_plot_ready = df.copy() \n",
    "    if df_plot_ready.empty: print(f\"  Manhattan: No valid interaction_Adj_Pval values after coercion.\"); return\n",
    "    \n",
    "    df_plot_ready['-logP_Overlap'] = -np.log10(df_plot_ready['interaction_Adj_Pval'] + np.finfo(float).tiny) \n",
    "    df_plot_ready['Label'] = df_plot_ready['TF'] + \" - \" + df_plot_ready['Pathway_Name'] \n",
    "    df_plot_ready = df_plot_ready.sort_values(by=['Pathway_DB','Label']); df_plot_ready['x'] = range(len(df_plot_ready))\n",
    "    \n",
    "    dbs = sorted(df_plot_ready['Pathway_DB'].unique())\n",
    "    cmap = plt.colormaps['tab10'] if len(dbs)<=10 else plt.colormaps['tab20']\n",
    "    cols = cmap(np.linspace(0,1,len(dbs))); db_cols = {db:cols[i] for i,db in enumerate(dbs)}\n",
    "    df_plot_ready['color'] = df_plot_ready['Pathway_DB'].map(db_cols)\n",
    "    \n",
    "    if 'N_Shared' in df_plot_ready.columns and df_plot_ready['N_Shared'].notna().all() and df_plot_ready['N_Shared'].nunique()>1:\n",
    "        min_s,max_s=df_plot_ready['N_Shared'].min(),df_plot_ready['N_Shared'].max()\n",
    "        df_plot_ready['size']=150*(df_plot_ready['N_Shared']-min_s+1e-6)/(max_s-min_s+1e-6); df_plot_ready['size']=np.maximum(20,df_plot_ready['size'])\n",
    "    else: df_plot_ready['size']=50\n",
    "        \n",
    "    figsize_width = min(100, max(15, len(df_plot_ready) * 0.05)) # Capped width\n",
    "    plt.figure(figsize=(figsize_width, 7))\n",
    "    plt.axhline(-np.log10(sig_thr),c='r',ls='--',lw=1,label=f'Adj. P-val = {sig_thr}') \n",
    "    plt.scatter(df_plot_ready['x'],df_plot_ready['-logP_Overlap'],c=df_plot_ready['color'],s=df_plot_ready['size'],alpha=.7,ec='k',lw=.5)\n",
    "    \n",
    "    lab_df = df_plot_ready[df_plot_ready['interaction_Adj_Pval']<lab_thr].sort_values(by='-logP_Overlap',ascending=False).head(n_lab)\n",
    "    txts = [plt.text(r['x'],r['-logP_Overlap'],f\"{str(r['TF'])[:10]}...\\n{str(r['Pathway_Name'])[:15]}...\",fontsize=5,ha='center') for _,r in lab_df.iterrows()]\n",
    "    if ADJUST_TEXT_AVAILABLE and txts: adjust_text(txts,arrowprops=dict(arrowstyle='-',color='grey',lw=.3))\n",
    "    \n",
    "    plt.xticks([]); plt.xlabel('TF-Pathway Links (Grouped by Pathway DB)',fontsize=9)\n",
    "    plt.ylabel('-log10 (TF-Pathway Overlap Adj. P-value)',fontsize=9); \n",
    "    plt.title(f'TF-Pathway Links: {cell_type} ({tf_tool})',fontsize=11)\n",
    "    plt.ylim(bottom=0); plt.grid(axis='y',ls='--',alpha=.6)\n",
    "    hndls = [plt.Line2D([0],[0],marker='o',c='w',label=db,markerfacecolor=c,ms=7) for db,c in db_cols.items()]\n",
    "    plt.legend(handles=hndls,title=\"Pathway DB\",bbox_to_anchor=(1.02,1),loc='upper left',fontsize=7)\n",
    "    plt.tight_layout(rect=[0,0,0.88,1])\n",
    "    for ext in ['svg','pdf']:\n",
    "        fpath = os.path.join(plot_dir,f\"{tf_tool}_{cell_type}_tf_path_manhattan.{ext}\")\n",
    "        plt.savefig(fpath); print(f\"  Saved Manhattan: {fpath}\")\n",
    "    plt.close()\n",
    "\n",
    "def plot_tf_path_network(links_df, cell_type, tf_tool, top_n_links=30):\n",
    "    \"\"\"Generates a bipartite network plot of TF-Pathway links.\"\"\"\n",
    "    if links_df.empty or not all(c in links_df.columns for c in ['TF', 'Pathway_Name', 'interaction_Adj_Pval']):\n",
    "        print(f\"  Network: Invalid data for {cell_type} ({tf_tool}). Skipping.\"); return\n",
    "    print(f\"--- Plotting TF-Pathway Network: {cell_type} ({tf_tool}) ---\")\n",
    "    plot_dir = os.path.join(output_dir, tf_tool, \"figures\")\n",
    "    os.makedirs(plot_dir, exist_ok=True)\n",
    "\n",
    "    plot_df = links_df.nsmallest(top_n_links, 'interaction_Adj_Pval').copy()\n",
    "    if plot_df.empty: print(f\"  Network: No links after filtering top {top_n_links}.\"); return\n",
    "\n",
    "    plot_df['-logP_Overlap'] = -np.log10(plot_df['interaction_Adj_Pval'] + np.finfo(float).tiny)\n",
    "    \n",
    "    B = nx.Graph()\n",
    "    tfs_in_plot = plot_df['TF'].unique()\n",
    "    pathways_in_plot = plot_df['Pathway_Name'].unique()\n",
    "    B.add_nodes_from(tfs_in_plot, bipartite=0, type='TF')\n",
    "    B.add_nodes_from(pathways_in_plot, bipartite=1, type='Pathway')\n",
    "\n",
    "    edge_weights_for_viz = []\n",
    "    for _, row in plot_df.iterrows():\n",
    "        B.add_edge(row['TF'], row['Pathway_Name'], weight=row['-logP_Overlap'])\n",
    "        edge_weights_for_viz.append(row['-logP_Overlap'])\n",
    "    \n",
    "    if not B.edges(): print(f\"  Network: No edges formed for {cell_type} ({tf_tool}).\"); return\n",
    "\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    pos = nx.spring_layout(B, k=0.6, iterations=70, seed=42) \n",
    "\n",
    "    tf_nodes = [n for n, d in B.nodes(data=True) if d['bipartite']==0]\n",
    "    path_nodes = [n for n, d in B.nodes(data=True) if d['bipartite']==1]\n",
    "    \n",
    "    node_degrees = [B.degree(n) for n in B.nodes()]\n",
    "    min_degree = min(node_degrees) if node_degrees else 1\n",
    "    max_degree = max(node_degrees) if node_degrees else 1\n",
    "    node_sizes_map = {n: 100 + 1500 * (B.degree(n) - min_degree) / (max_degree - min_degree + 1e-6) if max_degree > min_degree else 100 + 1500 * 0.5 for n in B.nodes()}\n",
    "    node_sizes_tf = [max(node_sizes_map.get(n, 100), 100) for n in tf_nodes]\n",
    "    node_sizes_path = [max(node_sizes_map.get(n, 100), 100) for n in path_nodes]\n",
    "\n",
    "    nx.draw_networkx_nodes(B, pos, nodelist=tf_nodes, node_color='skyblue', node_size=node_sizes_tf, alpha=0.9)\n",
    "    nx.draw_networkx_nodes(B, pos, nodelist=path_nodes, node_color='lightgreen', node_size=node_sizes_path, alpha=0.9)\n",
    "    \n",
    "    if edge_weights_for_viz:\n",
    "        min_w, max_w = min(edge_weights_for_viz), max(edge_weights_for_viz)\n",
    "        norm_widths = [0.5 + 3*(w-min_w)/(max_w-min_w+1e-6) for w in edge_weights_for_viz] if max_w > min_w else [1]*len(edge_weights_for_viz)\n",
    "    else: norm_widths = []\n",
    "\n",
    "    nx.draw_networkx_edges(B, pos, width=norm_widths, alpha=0.4, edge_color='dimgray')\n",
    "    nx.draw_networkx_labels(B, pos, font_size=6, font_weight='normal')\n",
    "    \n",
    "    plt.title(f'Top {min(top_n_links, len(plot_df))} TF-Pathway Links: {cell_type} ({tf_tool})', fontsize=14)\n",
    "    plt.axis('off')\n",
    "    tf_patch = plt.Line2D([0], [0], marker='o', color='w', label='TF', markersize=10, markerfacecolor='skyblue')\n",
    "    path_patch = plt.Line2D([0], [0], marker='o', color='w', label='Pathway', markersize=10, markerfacecolor='lightgreen')\n",
    "    plt.legend(handles=[tf_patch, path_patch], loc='best', fontsize=9)\n",
    "    plt.tight_layout()\n",
    "    for ext in ['svg','pdf']:\n",
    "        fpath = os.path.join(plot_dir,f\"{cell_type}_tf_path_network.{ext}\")\n",
    "        plt.savefig(fpath); print(f\"  Saved Network plot: {fpath}\")\n",
    "    plt.close()\n",
    "\n",
    "# --- DEG COVERAGE PLOTTING (Donut Plot Logic Revised) ---\n",
    "def plot_deg_pies(deg_list, cell_type, tf_results, top_n=TOP_N_PIE):\n",
    "    \"\"\"Generates DEG coverage pie charts for a cell type, with revised logic.\"\"\"\n",
    "    global output_dir\n",
    "    print(f\"--- Generating DEG Coverage Pie Charts for {cell_type} ---\")\n",
    "    explained_stats_for_summary_bar = {} \n",
    "    if not deg_list:\n",
    "        for method in tf_results.keys(): explained_stats_for_summary_bar[method] = 0.0\n",
    "        return explained_stats_for_summary_bar\n",
    "\n",
    "    deg_set = set(deg_list)\n",
    "    total_deg_count = len(deg_set)\n",
    "\n",
    "    for method, sig_tfs_df in tf_results.items():\n",
    "        print(f\"  Plotting for method: {method} ({cell_type})\")\n",
    "        plot_dir = os.path.join(output_dir, method, \"figures\")\n",
    "        os.makedirs(plot_dir, exist_ok=True)\n",
    "        \n",
    "        plot_title = f'DEG Coverage: {cell_type} ({method})'\n",
    "        pie_labels_final, pie_sizes_final_normalized = [], [] \n",
    "\n",
    "        if sig_tfs_df is None or sig_tfs_df.empty or not all(c in sig_tfs_df.columns for c in ['Term','Genes','Adjusted P-value']):\n",
    "            explained_stats_for_summary_bar[method] = 0.0\n",
    "            if total_deg_count > 0:\n",
    "                pie_labels_final, pie_sizes_final_normalized = ['Not Explained'], [100.0]\n",
    "                plot_title += '\\n(No significant TFs or malformed TF data)'\n",
    "            else: \n",
    "                print(f\"    No DEGs for {cell_type}, skipping pie for method {method}.\")\n",
    "                continue\n",
    "        else:\n",
    "            sorted_tfs = sig_tfs_df.sort_values(by='Adjusted P-value')\n",
    "            \n",
    "            degs_explained_by_any_tf = set()\n",
    "            for _, r_all_tf in sorted_tfs.iterrows():\n",
    "                if pd.notna(r_all_tf['Genes']) and r_all_tf['Genes'] != '':\n",
    "                    degs_explained_by_any_tf.update(deg_set.intersection(str(r_all_tf['Genes']).split(';')))\n",
    "            \n",
    "            num_total_explained_degs = len(degs_explained_by_any_tf)\n",
    "            # This is the overall % of DEGs explained by this method, for the summary bar\n",
    "            explained_stats_for_summary_bar[method] = (num_total_explained_degs / total_deg_count) * 100 if total_deg_count > 0 else 0.0\n",
    "            \n",
    "            # Slices for the pie chart (raw percentages of total DEGs)\n",
    "            current_pie_slices_raw_pct = {} # Using dict to manage named slices before ordering\n",
    "\n",
    "            # 1. Top N TF Slices\n",
    "            degs_covered_by_top_n_explicitly_shown = set()\n",
    "            for _, r_top_tf in sorted_tfs.head(top_n).iterrows():\n",
    "                tf_name = r_top_tf['Term']\n",
    "                tf_genes_str = str(r_top_tf.get('Genes', ''))\n",
    "                if tf_genes_str:\n",
    "                    degs_for_this_tf = deg_set.intersection(tf_genes_str.split(';'))\n",
    "                    if degs_for_this_tf: \n",
    "                        pct_contribution = (len(degs_for_this_tf) / total_deg_count) * 100 if total_deg_count > 0 else 0.0\n",
    "                        if pct_contribution > 0.01: \n",
    "                            current_pie_slices_raw_pct[tf_name] = pct_contribution\n",
    "                            degs_covered_by_top_n_explicitly_shown.update(degs_for_this_tf)\n",
    "            \n",
    "            # 2. \"Other Explained TFs\" Slice\n",
    "            degs_for_other_tfs_slice = degs_explained_by_any_tf - degs_covered_by_top_n_explicitly_shown\n",
    "            percent_others_explained = (len(degs_for_other_tfs_slice) / total_deg_count) * 100 if total_deg_count > 0 else 0.0\n",
    "            if percent_others_explained > 0.01:\n",
    "                current_pie_slices_raw_pct['Other TFs'] = percent_others_explained\n",
    "            \n",
    "            # 3. \"Not Explained\" Slice\n",
    "            num_not_explained = total_deg_count - num_total_explained_degs\n",
    "            percent_not_explained = (num_not_explained / total_deg_count) * 100 if total_deg_count > 0 else 0.0\n",
    "            if percent_not_explained > 0.01 or not current_pie_slices_raw_pct: # Add if meaningful or only category\n",
    "                current_pie_slices_raw_pct['Not Explained'] = percent_not_explained\n",
    "            \n",
    "            plot_title = f'DEG Coverage by Top {top_n} TFs: {cell_type} ({method})'\n",
    "\n",
    "            # Prepare final labels and sizes for plotting, ensuring order\n",
    "            pie_labels_final = list(current_pie_slices_raw_pct.keys())\n",
    "            pie_sizes_raw_pct_total_degs = list(current_pie_slices_raw_pct.values())\n",
    "\n",
    "            # Normalize pie_sizes_raw_pct_total_degs to sum to 100% for the pie chart display\n",
    "            current_sum_pie = sum(pie_sizes_raw_pct_total_degs)\n",
    "            if current_sum_pie > 0:\n",
    "                pie_sizes_final_normalized = [(s / current_sum_pie) * 100 for s in pie_sizes_raw_pct_total_degs]\n",
    "            elif total_deg_count > 0 : \n",
    "                pie_labels_final, pie_sizes_final_normalized = ['Not Explained'], [100.0]\n",
    "            else: # No DEGs and no slices\n",
    "                pie_labels_final, pie_sizes_final_normalized = [],[]\n",
    "        \n",
    "        if not pie_labels_final: \n",
    "            print(f\"    No data to plot in pie chart for {method}, {cell_type}.\")\n",
    "            continue\n",
    "\n",
    "        cmap = plt.colormaps['tab20'] if len(pie_labels_final)<=20 else plt.colormaps['viridis']\n",
    "        colors = cmap(np.linspace(0,1,len(pie_labels_final)))\n",
    "        fig,ax = plt.subplots(figsize=(10,8))\n",
    "        wedges,txs,auts = ax.pie(pie_sizes_final_normalized,autopct='%1.1f%%',startangle=140,colors=colors,wedgeprops={\"ec\":\"w\",'lw':.7,'antialiased':True},pctdistance=.85)\n",
    "        for t in txs:t.set_fontsize(9)\n",
    "        for at in auts:at.set_color('white');at.set_fontsize(8);at.set_fontweight('bold')\n",
    "        ax.add_artist(plt.Circle((0,0),.7,fc='white')); ax.axis('equal'); ax.set_title(plot_title,fontsize=12)\n",
    "        ax.legend(wedges,pie_labels_final,title=\"Categories\",loc=\"center left\",bbox_to_anchor=(1,0,.5,1),fontsize=9)\n",
    "        plt.tight_layout(rect=[0,0,.85,1])\n",
    "        for ext in ['svg','pdf']:\n",
    "            fpath = os.path.join(plot_dir,f\"{method}_{cell_type}_deg_cov_pie.{ext}\") \n",
    "            plt.savefig(fpath); print(f\"    Pie chart ({ext.upper()}) saved: {fpath}\")\n",
    "        plt.close(fig)\n",
    "    return explained_stats_for_summary_bar\n",
    "\n",
    "def plot_summary_bars(all_cov_stats, ordered_cts):\n",
    "    global output_dir\n",
    "    print(\"\\n--- Generating Summary DEG Coverage Stacked Bars ---\")\n",
    "    if not all_cov_stats: print(\"No data for summary. Skipping.\"); return\n",
    "    tf_methods = set(m for d in all_cov_stats.values() if isinstance(d,dict) for m in d.keys())\n",
    "    if not tf_methods: print(\"No TF methods in data. Skipping.\"); return\n",
    "\n",
    "    for method in sorted(list(tf_methods)):\n",
    "        plot_dir = os.path.join(output_dir, method, \"figures\")\n",
    "        os.makedirs(plot_dir, exist_ok=True)\n",
    "        \n",
    "        print(f\"  Bar plot for: {method}\")\n",
    "        data = {ct:all_cov_stats.get(ct,{}).get(method,0.0) for ct in ordered_cts}\n",
    "        if not data: continue\n",
    "        df = pd.DataFrame.from_dict(data,orient='index',columns=['Explained (%)']).reindex(ordered_cts)\n",
    "        df['Not Explained (%)'] = 100-df['Explained (%)']\n",
    "        fig,ax = plt.subplots(figsize=(max(8,len(ordered_cts)*.7),7))\n",
    "        ax.bar(df.index,df['Explained (%)'],label=f'Explained ({method})',color='skyblue')\n",
    "        ax.bar(df.index,df['Not Explained (%)'],bottom=df['Explained (%)'],label='Not Explained',color='lightcoral')\n",
    "        ax.set_xlabel('Cell Type'); ax.set_ylabel('% DEGs'); ax.set_title(f'DEG Coverage ({method})',fontsize=14)\n",
    "        ax.tick_params(axis='x',rotation=45); ax.legend(loc='upper right'); ax.grid(axis='y',ls='--',alpha=.7)\n",
    "        for label in ax.get_xticklabels():\n",
    "            label.set_ha('right')\n",
    "        plt.tight_layout()\n",
    "        for ext in ['svg','pdf']:\n",
    "            fpath = os.path.join(plot_dir,f\"{method}_summary_bars.{ext}\") \n",
    "            plt.savefig(fpath); print(f\"    Stacked bar saved: {fpath}\")\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0893cfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_manhattan_ind(links_df, cell_type, tf_tool, save_path, sig_thr=SIGNIFICANCE_CUTOFF, n_lab=TOP_N_LABEL, lab_thr=LABEL_QVAL_THRESHOLD):\n",
    "    \"\"\"Creates Manhattan-style plot for TF-Pathway links, y-axis is interaction_Adj_Pval.\"\"\"\n",
    "    if links_df.empty or 'interaction_Adj_Pval' not in links_df.columns or 'Pathway_DB' not in links_df.columns:\n",
    "        print(f\"  Manhattan: Invalid data for {cell_type} ({tf_tool}). Missing 'interaction_Adj_Pval' or 'Pathway_DB'. Skipping.\"); return\n",
    "    print(f\"--- Plotting Manhattan: {cell_type} ({tf_tool}) ---\")\n",
    "    plot_dir = os.path.join(save_path, tf_tool, \"figures\")\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "    df = links_df.copy(); \n",
    "    df['interaction_Adj_Pval'] = pd.to_numeric(df['interaction_Adj_Pval'],errors='coerce')\n",
    "    df.dropna(subset=['interaction_Adj_Pval'],inplace=True)\n",
    "    df_plot_ready = df.copy() \n",
    "    if df_plot_ready.empty: print(f\"  Manhattan: No valid interaction_Adj_Pval values after coercion.\"); return\n",
    "    \n",
    "    df_plot_ready['-logP_Overlap'] = -np.log10(df_plot_ready['interaction_Adj_Pval'] + np.finfo(float).tiny) \n",
    "    df_plot_ready['Label'] = df_plot_ready['TF'] + \" - \" + df_plot_ready['Pathway_Name'] \n",
    "    df_plot_ready = df_plot_ready.sort_values(by=['Pathway_DB','Label']); df_plot_ready['x'] = range(len(df_plot_ready))\n",
    "    \n",
    "    dbs = sorted(df_plot_ready['Pathway_DB'].unique())\n",
    "    cmap = plt.colormaps['tab10'] if len(dbs)<=10 else plt.colormaps['tab20']\n",
    "    cols = cmap(np.linspace(0,1,len(dbs))); db_cols = {db:cols[i] for i,db in enumerate(dbs)}\n",
    "    df_plot_ready['color'] = df_plot_ready['Pathway_DB'].map(db_cols)\n",
    "    \n",
    "    if 'N_Shared' in df_plot_ready.columns and df_plot_ready['N_Shared'].notna().all() and df_plot_ready['N_Shared'].nunique()>1:\n",
    "        min_s,max_s=df_plot_ready['N_Shared'].min(),df_plot_ready['N_Shared'].max()\n",
    "        df_plot_ready['size']=150*(df_plot_ready['N_Shared']-min_s+1e-6)/(max_s-min_s+1e-6); df_plot_ready['size']=np.maximum(20,df_plot_ready['size'])\n",
    "    else: df_plot_ready['size']=50\n",
    "        \n",
    "    figsize_width = min(100, max(15, len(df_plot_ready) * 0.05)) # Capped width\n",
    "    plt.figure(figsize=(figsize_width, 7))\n",
    "    plt.axhline(-np.log10(sig_thr),c='r',ls='--',lw=1,label=f'Adj. P-val = {sig_thr}') \n",
    "    plt.scatter(df_plot_ready['x'],df_plot_ready['-logP_Overlap'],c=df_plot_ready['color'],s=df_plot_ready['size'],alpha=.7,ec='k',lw=.5)\n",
    "    \n",
    "    lab_df = df_plot_ready[df_plot_ready['interaction_Adj_Pval']<lab_thr].sort_values(by='-logP_Overlap',ascending=False).head(n_lab)\n",
    "    txts = [plt.text(r['x'],r['-logP_Overlap'],f\"{str(r['TF'])[:10]}...\\n{str(r['Pathway_Name'])[:15]}...\",fontsize=5,ha='center') for _,r in lab_df.iterrows()]\n",
    "    if ADJUST_TEXT_AVAILABLE and txts: adjust_text(txts,arrowprops=dict(arrowstyle='-',color='grey',lw=.3))\n",
    "    \n",
    "    plt.xticks([]); plt.xlabel('TF-Pathway Links (Grouped by Pathway DB)',fontsize=9)\n",
    "    plt.ylabel('-log10 (TF-Pathway Overlap Adj. P-value)',fontsize=9); \n",
    "    plt.title(f'TF-Pathway Links: {cell_type} ({tf_tool})',fontsize=11)\n",
    "    plt.ylim(bottom=0); plt.grid(axis='y',ls='--',alpha=.6)\n",
    "    hndls = [plt.Line2D([0],[0],marker='o',c='w',label=db,markerfacecolor=c,ms=7) for db,c in db_cols.items()]\n",
    "    plt.legend(handles=hndls,title=\"Pathway DB\",bbox_to_anchor=(1.02,1),loc='upper left',fontsize=7)\n",
    "    plt.tight_layout(rect=[0,0,0.88,1])\n",
    "    for ext in ['svg','pdf']:\n",
    "        fpath = os.path.join(plot_dir,f\"{tf_tool}_{cell_type}_tf_path_manhattan.{ext}\")\n",
    "        plt.savefig(fpath); print(f\"  Saved Manhattan: {fpath}\")\n",
    "    plt.close()\n",
    "\n",
    "def plot_tf_path_network_ind(links_df, cell_type, tf_tool, save_path, top_n_links=30):\n",
    "    \"\"\"Generates a bipartite network plot of TF-Pathway links.\"\"\"\n",
    "    if links_df.empty or not all(c in links_df.columns for c in ['TF', 'Pathway_Name', 'interaction_Adj_Pval']):\n",
    "        print(f\"  Network: Invalid data for {cell_type} ({tf_tool}). Skipping.\"); return\n",
    "    print(f\"--- Plotting TF-Pathway Network: {cell_type} ({tf_tool}) ---\")\n",
    "    plot_dir = os.path.join(save_path, tf_tool, \"figures\")\n",
    "    os.makedirs(plot_dir, exist_ok=True)\n",
    "\n",
    "    plot_df = links_df.nsmallest(top_n_links, 'interaction_Adj_Pval').copy()\n",
    "    if plot_df.empty: print(f\"  Network: No links after filtering top {top_n_links}.\"); return\n",
    "\n",
    "    plot_df['-logP_Overlap'] = -np.log10(plot_df['interaction_Adj_Pval'] + np.finfo(float).tiny)\n",
    "    \n",
    "    B = nx.Graph()\n",
    "    tfs_in_plot = plot_df['TF'].unique()\n",
    "    pathways_in_plot = plot_df['Pathway_Name'].unique()\n",
    "    B.add_nodes_from(tfs_in_plot, bipartite=0, type='TF')\n",
    "    B.add_nodes_from(pathways_in_plot, bipartite=1, type='Pathway')\n",
    "\n",
    "    edge_weights_for_viz = []\n",
    "    for _, row in plot_df.iterrows():\n",
    "        B.add_edge(row['TF'], row['Pathway_Name'], weight=row['-logP_Overlap'])\n",
    "        edge_weights_for_viz.append(row['-logP_Overlap'])\n",
    "    \n",
    "    if not B.edges(): print(f\"  Network: No edges formed for {cell_type} ({tf_tool}).\"); return\n",
    "\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    pos = nx.spring_layout(B, k=0.6, iterations=70, seed=42) \n",
    "\n",
    "    tf_nodes = [n for n, d in B.nodes(data=True) if d['bipartite']==0]\n",
    "    path_nodes = [n for n, d in B.nodes(data=True) if d['bipartite']==1]\n",
    "    \n",
    "    node_degrees = [B.degree(n) for n in B.nodes()]\n",
    "    min_degree = min(node_degrees) if node_degrees else 1\n",
    "    max_degree = max(node_degrees) if node_degrees else 1\n",
    "    node_sizes_map = {n: 100 + 1500 * (B.degree(n) - min_degree) / (max_degree - min_degree + 1e-6) if max_degree > min_degree else 100 + 1500 * 0.5 for n in B.nodes()}\n",
    "    node_sizes_tf = [max(node_sizes_map.get(n, 100), 100) for n in tf_nodes]\n",
    "    node_sizes_path = [max(node_sizes_map.get(n, 100), 100) for n in path_nodes]\n",
    "\n",
    "    nx.draw_networkx_nodes(B, pos, nodelist=tf_nodes, node_color='skyblue', node_size=node_sizes_tf, alpha=0.9)\n",
    "    nx.draw_networkx_nodes(B, pos, nodelist=path_nodes, node_color='lightgreen', node_size=node_sizes_path, alpha=0.9)\n",
    "    \n",
    "    if edge_weights_for_viz:\n",
    "        min_w, max_w = min(edge_weights_for_viz), max(edge_weights_for_viz)\n",
    "        norm_widths = [0.5 + 3*(w-min_w)/(max_w-min_w+1e-6) for w in edge_weights_for_viz] if max_w > min_w else [1]*len(edge_weights_for_viz)\n",
    "    else: norm_widths = []\n",
    "\n",
    "    nx.draw_networkx_edges(B, pos, width=norm_widths, alpha=0.4, edge_color='dimgray')\n",
    "    nx.draw_networkx_labels(B, pos, font_size=6, font_weight='normal')\n",
    "    \n",
    "    plt.title(f'Top {min(top_n_links, len(plot_df))} TF-Pathway Links: {cell_type} ({tf_tool})', fontsize=14)\n",
    "    plt.axis('off')\n",
    "    tf_patch = plt.Line2D([0], [0], marker='o', color='w', label='TF', markersize=10, markerfacecolor='skyblue')\n",
    "    path_patch = plt.Line2D([0], [0], marker='o', color='w', label='Pathway', markersize=10, markerfacecolor='lightgreen')\n",
    "    plt.legend(handles=[tf_patch, path_patch], loc='best', fontsize=9)\n",
    "    plt.tight_layout()\n",
    "    for ext in ['svg','pdf']:\n",
    "        fpath = os.path.join(plot_dir,f\"{cell_type}_tf_path_network.{ext}\")\n",
    "        plt.savefig(fpath); print(f\"  Saved Network plot: {fpath}\")\n",
    "    plt.close()\n",
    "\n",
    "# --- DEG COVERAGE PLOTTING (Donut Plot Logic Revised) ---\n",
    "def plot_deg_pies_ind(deg_list, cell_type, sig_tfs_df, tf_tool, save_path, top_n=TOP_N_PIE):\n",
    "    \"\"\"Generates DEG coverage pie charts for a cell type, with revised logic.\"\"\"\n",
    "    global output_dir\n",
    "    print(f\"--- Generating DEG Coverage Pie Charts for {cell_type} ---\")\n",
    "    method = tf_tool\n",
    "    explained_stats_for_summary_bar = {} \n",
    "    if not deg_list:\n",
    "        explained_stats_for_summary_bar[method] = 0.0\n",
    "        return explained_stats_for_summary_bar\n",
    "\n",
    "    deg_set = set(deg_list)\n",
    "    total_deg_count = len(deg_set)\n",
    "    \n",
    "    print(f\"  Plotting for method: {method} ({cell_type})\")\n",
    "    plot_dir = os.path.join(save_path, method, \"figures\")\n",
    "    os.makedirs(plot_dir, exist_ok=True)\n",
    "    \n",
    "    plot_title = f'DEG Coverage: {cell_type} ({method})'\n",
    "    pie_labels_final, pie_sizes_final_normalized = [], [] \n",
    "    \n",
    "    if sig_tfs_df is None or sig_tfs_df.empty or not all(c in sig_tfs_df.columns for c in ['Term','Genes','Adjusted P-value']):\n",
    "        explained_stats_for_summary_bar[method] = 0.0\n",
    "        if total_deg_count > 0:\n",
    "            pie_labels_final, pie_sizes_final_normalized = ['Not Explained'], [100.0]\n",
    "            plot_title += '\\n(No significant TFs or malformed TF data)'\n",
    "        else: \n",
    "            print(f\"    No DEGs for {cell_type}, skipping pie for method {method}.\")\n",
    "    else:\n",
    "        sorted_tfs = sig_tfs_df.sort_values(by='Adjusted P-value')\n",
    "        \n",
    "        degs_explained_by_any_tf = set()\n",
    "        for _, r_all_tf in sorted_tfs.iterrows():\n",
    "            if pd.notna(r_all_tf['Genes']) and r_all_tf['Genes'] != '':\n",
    "                degs_explained_by_any_tf.update(deg_set.intersection(str(r_all_tf['Genes']).split(';')))\n",
    "        \n",
    "        num_total_explained_degs = len(degs_explained_by_any_tf)\n",
    "        # This is the overall % of DEGs explained by this method, for the summary bar\n",
    "        explained_stats_for_summary_bar[method] = (num_total_explained_degs / total_deg_count) * 100 if total_deg_count > 0 else 0.0\n",
    "        \n",
    "        # Slices for the pie chart (raw percentages of total DEGs)\n",
    "        current_pie_slices_raw_pct = {} # Using dict to manage named slices before ordering\n",
    "\n",
    "        # 1. Top N TF Slices\n",
    "        degs_covered_by_top_n_explicitly_shown = set()\n",
    "        for _, r_top_tf in sorted_tfs.head(top_n).iterrows():\n",
    "            tf_name = r_top_tf['Term']\n",
    "            tf_genes_str = str(r_top_tf.get('Genes', ''))\n",
    "            if tf_genes_str:\n",
    "                degs_for_this_tf = deg_set.intersection(tf_genes_str.split(';'))\n",
    "                if degs_for_this_tf: \n",
    "                    pct_contribution = (len(degs_for_this_tf) / total_deg_count) * 100 if total_deg_count > 0 else 0.0\n",
    "                    if pct_contribution > 0.01: \n",
    "                        current_pie_slices_raw_pct[tf_name] = pct_contribution\n",
    "                        degs_covered_by_top_n_explicitly_shown.update(degs_for_this_tf)\n",
    "        \n",
    "        # 2. \"Other Explained TFs\" Slice\n",
    "        degs_for_other_tfs_slice = degs_explained_by_any_tf - degs_covered_by_top_n_explicitly_shown\n",
    "        percent_others_explained = (len(degs_for_other_tfs_slice) / total_deg_count) * 100 if total_deg_count > 0 else 0.0\n",
    "        if percent_others_explained > 0.01:\n",
    "            current_pie_slices_raw_pct['Other TFs'] = percent_others_explained\n",
    "        \n",
    "        # 3. \"Not Explained\" Slice\n",
    "        num_not_explained = total_deg_count - num_total_explained_degs\n",
    "        percent_not_explained = (num_not_explained / total_deg_count) * 100 if total_deg_count > 0 else 0.0\n",
    "        if percent_not_explained > 0.01 or not current_pie_slices_raw_pct: # Add if meaningful or only category\n",
    "            current_pie_slices_raw_pct['Not Explained'] = percent_not_explained\n",
    "        \n",
    "        plot_title = f'DEG Coverage by Top {top_n} TFs: {cell_type} ({method})'\n",
    "\n",
    "        # Prepare final labels and sizes for plotting, ensuring order\n",
    "        pie_labels_final = list(current_pie_slices_raw_pct.keys())\n",
    "        pie_sizes_raw_pct_total_degs = list(current_pie_slices_raw_pct.values())\n",
    "\n",
    "        # Normalize pie_sizes_raw_pct_total_degs to sum to 100% for the pie chart display\n",
    "        current_sum_pie = sum(pie_sizes_raw_pct_total_degs)\n",
    "        if current_sum_pie > 0:\n",
    "            pie_sizes_final_normalized = [(s / current_sum_pie) * 100 for s in pie_sizes_raw_pct_total_degs]\n",
    "        elif total_deg_count > 0 : \n",
    "            pie_labels_final, pie_sizes_final_normalized = ['Not Explained'], [100.0]\n",
    "        else: # No DEGs and no slices\n",
    "            pie_labels_final, pie_sizes_final_normalized = [],[]\n",
    "    \n",
    "    if not pie_labels_final: \n",
    "        print(f\"    No data to plot in pie chart for {method}, {cell_type}.\")\n",
    "\n",
    "    cmap = plt.colormaps['tab20'] if len(pie_labels_final)<=20 else plt.colormaps['viridis']\n",
    "    colors = cmap(np.linspace(0,1,len(pie_labels_final)))\n",
    "    fig,ax = plt.subplots(figsize=(10,8))\n",
    "    wedges,txs,auts = ax.pie(pie_sizes_final_normalized,autopct='%1.1f%%',startangle=140,colors=colors,wedgeprops={\"ec\":\"w\",'lw':.7,'antialiased':True},pctdistance=.85)\n",
    "    for t in txs:t.set_fontsize(9)\n",
    "    for at in auts:at.set_color('white');at.set_fontsize(8);at.set_fontweight('bold')\n",
    "    ax.add_artist(plt.Circle((0,0),.7,fc='white')); ax.axis('equal'); ax.set_title(plot_title,fontsize=12)\n",
    "    ax.legend(wedges,pie_labels_final,title=\"Categories\",loc=\"center left\",bbox_to_anchor=(1,0,.5,1),fontsize=9)\n",
    "    plt.tight_layout(rect=[0,0,.85,1])\n",
    "    for ext in ['svg','pdf']:\n",
    "        fpath = os.path.join(plot_dir,f\"{method}_{cell_type}_deg_cov_pie.{ext}\") \n",
    "        plt.savefig(fpath); print(f\"    Pie chart ({ext.upper()}) saved: {fpath}\")\n",
    "    plt.close(fig)\n",
    "    return explained_stats_for_summary_bar\n",
    "\n",
    "def plot_summary_bars_ind(all_cov_stats, ordered_cts, tf_tool, save_path):\n",
    "    global output_dir\n",
    "    print(\"\\n--- Generating Summary DEG Coverage Stacked Bars ---\")\n",
    "    if not all_cov_stats: print(\"No data for summary. Skipping.\"); return\n",
    "    tf_methods = set(m for d in all_cov_stats.values() if isinstance(d,dict) for m in d.keys())\n",
    "    if not tf_methods: print(\"No TF methods in data. Skipping.\"); return\n",
    "    method = tf_tool\n",
    "   \n",
    "    plot_dir = os.path.join(save_path, method, \"figures\")\n",
    "    os.makedirs(plot_dir, exist_ok=True)\n",
    "    \n",
    "    print(f\"  Bar plot for: {method}\")\n",
    "    data = {ct:all_cov_stats.get(ct,{}).get(method,0.0) for ct in ordered_cts}\n",
    "\n",
    "    df = pd.DataFrame.from_dict(data,orient='index',columns=['Explained (%)']).reindex(ordered_cts)\n",
    "    df['Not Explained (%)'] = 100-df['Explained (%)']\n",
    "    fig,ax = plt.subplots(figsize=(max(8,len(ordered_cts)*.7),7))\n",
    "    ax.bar(df.index,df['Explained (%)'],label=f'Explained ({method})',color='skyblue')\n",
    "    ax.bar(df.index,df['Not Explained (%)'],bottom=df['Explained (%)'],label='Not Explained',color='lightcoral')\n",
    "    ax.set_xlabel('Cell Type'); ax.set_ylabel('% DEGs'); ax.set_title(f'DEG Coverage ({method})',fontsize=14)\n",
    "    ax.tick_params(axis='x',rotation=45); ax.legend(loc='upper right'); ax.grid(axis='y',ls='--',alpha=.7)\n",
    "    for label in ax.get_xticklabels():\n",
    "        label.set_ha('right')\n",
    "    plt.tight_layout()\n",
    "    for ext in ['svg','pdf']:\n",
    "        fpath = os.path.join(plot_dir,f\"{method}_summary_bars.{ext}\") \n",
    "        plt.savefig(fpath); print(f\"    Stacked bar saved: {fpath}\")\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dceba1b-5008-430d-837b-58e8e2582e42",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053429e4-b422-41c7-8c8b-7508e8daa1a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# --- MAIN WORKFLOW ---\n",
    "def main():\n",
    "    global output_dir, DEG_dir, DEG_SYMBOL_COL, cell_types, PATHWAY_FILES, SIGNIFICANCE_CUTOFF, TOP_N_PIE\n",
    "    \n",
    "    deg_file_infos = []\n",
    "    print(f\"Constructing DEG file paths based on `cell_types` list and expected naming convention.\")\n",
    "    for ct in cell_types:\n",
    "        # Construct filename directly using the original cell_type string\n",
    "        deg_filename = f\"cell_types_diffxpy_{ct}_diff_res.csv\" \n",
    "        deg_filepath = os.path.join(DEG_dir, deg_filename)\n",
    "        \n",
    "        if os.path.exists(deg_filepath):\n",
    "            deg_file_infos.append({'name': ct, 'path': deg_filepath})\n",
    "            print(f\"  Found DEG file for processing: {ct} at {deg_filepath}\")\n",
    "        else:\n",
    "            print(f\"  Warning: DEG file NOT FOUND for cell_type '{ct}' at expected path: {deg_filepath}\")\n",
    "            \n",
    "    if not deg_file_infos: \n",
    "        print(\"CRITICAL: No DEG files found based on the `cell_types` list and expected naming. Please check paths and filenames. Exiting.\")\n",
    "        return\n",
    "\n",
    "    all_ct_coverage_stats = {}\n",
    "    \n",
    "    for item in deg_file_infos:\n",
    "        cell_type = item['name'] \n",
    "        print(f\"\\n\\n<<<< Processing cell type: {cell_type} >>>>\")\n",
    "        \n",
    "        try:\n",
    "            deg_df = pd.read_csv(item['path'])\n",
    "            if DEG_SYMBOL_COL not in deg_df.columns:\n",
    "                print(f\"  Error: Gene symbol column '{DEG_SYMBOL_COL}' missing in {item['path']}. Skipping.\"); continue\n",
    "            current_degs = deg_df[DEG_SYMBOL_COL].dropna().astype(str).unique().tolist()\n",
    "        except Exception as e: print(f\"  Error loading DEGs for {cell_type}: {e}\"); current_degs = []\n",
    "\n",
    "        if not current_degs:\n",
    "            print(f\"  No DEGs for {cell_type}. Skipping.\"); all_ct_coverage_stats[cell_type] = {}; continue\n",
    "        print(f\"  Loaded {len(current_degs)} DEGs for {cell_type}.\")\n",
    "\n",
    "        ct_bg_genes = []\n",
    "        # Construct background filename directly using original cell_type string\n",
    "        bg_file = os.path.join(DEG_dir, f\"cell_types_diffxpy_{cell_type}_res-table.csv\")\n",
    "        try:\n",
    "            if os.path.exists(bg_file):\n",
    "                bg_df = pd.read_csv(bg_file)\n",
    "                if DEG_SYMBOL_COL in bg_df.columns:\n",
    "                    ct_bg_genes = list(set(bg_df[DEG_SYMBOL_COL].dropna().astype(str)))\n",
    "                    print(f\"  Loaded {len(ct_bg_genes)} background genes for {cell_type} from {bg_file}\")\n",
    "                else: print(f\"  Warning: Gene symbol column '{DEG_SYMBOL_COL}' not in background file {bg_file}.\")\n",
    "            else: print(f\"  Warning: Background file {bg_file} not found for {cell_type}.\")\n",
    "        except Exception as e_bg: print(f\"  Warning: Error loading background {bg_file}: {e_bg}\")\n",
    "        if not ct_bg_genes: print(f\"  Warning: Using empty background for {cell_type} for tools that require it (g:Profiler will use its default).\")\n",
    "\n",
    "        tf_libs = ['ChEA_2022','TRRUST_Transcription_Factors_2019','ENCODE_and_ChEA_Consensus_TFs_from_ChIP-X','ARCHS4_TFs_Coexp','TRANSFAC_and_JASPAR_PWMs']\n",
    "        sig_tfs_gseapy = run_gseapy_enrichment(current_degs, cell_type, tf_libs)\n",
    "\n",
    "        tf_results = {'gseapy': sig_tfs_gseapy}\n",
    "        ct_coverage_stats = plot_deg_pies(current_degs, cell_type, tf_results, top_n=TOP_N_PIE)\n",
    "        all_ct_coverage_stats[cell_type] = ct_coverage_stats\n",
    "\n",
    "        print(f\"\\n  --- Loading & Integrating Pathways for {cell_type} ---\")\n",
    "        ct_paths_list = [load_pathways(cell_type, pt_type) for pt_type in PATHWAY_FILES.keys()]\n",
    "        try:\n",
    "            ct_paths_df = pd.concat([df for df in ct_paths_list if df is not None and not df.empty], ignore_index=True) if ct_paths_list else pd.DataFrame()\n",
    "        except Exception as e_ct: print(f\"  Warning: No significant pathways for: {item}\")\n",
    "\n",
    "        if not ct_paths_df.empty:\n",
    "            print(f\"    Consolidated {len(ct_paths_df)} significant pathways for {cell_type}.\")\n",
    "            for tool, sig_tfs in tf_results.items():\n",
    "                if sig_tfs is not None and not sig_tfs.empty:\n",
    "                    links = integrate_tf_path(sig_tfs, ct_paths_df, cell_type, current_degs, tool, interaction_qval_cutoff=0.01, overlap_fraction_threshold=0.1)\n",
    "                    if links is not None and not links.empty:\n",
    "                        plot_manhattan(links, cell_type, tool)\n",
    "                        plot_tf_path_network(links, cell_type, tool) \n",
    "        else: print(f\"    No pathways loaded for {cell_type}, skipping TF-Pathway integration.\")\n",
    "\n",
    "    plot_summary_bars(all_ct_coverage_stats, cell_types)\n",
    "    print(\"\\nWorkflow complete. Check output directory for results.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce4ad99-6364-44e4-8f2f-a2fc0ca39738",
   "metadata": {},
   "source": [
    "# Explorer data and visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4db9cb49-aba6-4617-8d71-54659d4ec932",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_libs = ['ChEA_2022','TRRUST_Transcription_Factors_2019','ENCODE_and_ChEA_Consensus_TFs_from_ChIP-X','ARCHS4_TFs_Coexp','TRANSFAC_and_JASPAR_PWMs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97ab9ac-382e-4adb-b70e-5c14f0097dd0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for lib in tf_libs:\n",
    "    path = os.path.join(output_dir, \"gseapy\")\n",
    "            \n",
    "    tf_results = {}\n",
    "    all_ct_coverage_stats = {}\n",
    "    for ct in cell_types:\n",
    "        #Load precalculated files\n",
    "        deg_filepath = os.path.join(DEG_dir, f\"cell_types_diffxpy_{ct}_diff_res.csv\")\n",
    "        deg_df = pd.read_csv(deg_filepath)\n",
    "        current_degs = deg_df[DEG_SYMBOL_COL].dropna().astype(str).unique().tolist()\n",
    "\n",
    "        tf = pd.read_csv(os.path.join(output_dir, 'gseapy', 'tables', f\"gseapy_{ct}_sig_tf.csv\"))\n",
    "        link = pd.read_csv(os.path.join(output_dir, 'gseapy', 'tables', f\"gseapy_{ct}_tf_path_links.csv\"))\n",
    "        \n",
    "        #Subset to lib     \n",
    "        tf_sub = tf[tf.Gene_set == lib]\n",
    "        tf_results[ct] = tf_sub\n",
    "        ct_coverage_stats = plot_deg_pies_ind(current_degs, ct, tf_sub, lib, path, top_n=TOP_N_PIE)\n",
    "        all_ct_coverage_stats[ct] = ct_coverage_stats\n",
    "        \n",
    "        link_sub = link[link.TF.isin(list(tf_sub.Term))]\n",
    "        plot_manhattan_ind(link_sub, ct, lib, path)\n",
    "        plot_tf_path_network_ind(link_sub, ct, lib, path, top_n_links=100) \n",
    "        \n",
    "        \n",
    "    plot_summary_bars_ind(all_ct_coverage_stats, cell_types, lib, path)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b536c08-da01-4ba6-9489-bb7c1255cbf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd249f49-41ef-4048-a879-7bba4a53be9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14b60280-ae9e-45b1-bf54-264eabe3d782",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cell Type</th>\n",
       "      <th>Significant TFs</th>\n",
       "      <th>Total Unique Pathways</th>\n",
       "      <th>Reactome</th>\n",
       "      <th>GO_BP</th>\n",
       "      <th>WP</th>\n",
       "      <th>KEGG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NSC1a</td>\n",
       "      <td>80</td>\n",
       "      <td>477</td>\n",
       "      <td>167</td>\n",
       "      <td>282</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NSC1b</td>\n",
       "      <td>84</td>\n",
       "      <td>652</td>\n",
       "      <td>215</td>\n",
       "      <td>400</td>\n",
       "      <td>16</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NSC2a</td>\n",
       "      <td>85</td>\n",
       "      <td>848</td>\n",
       "      <td>289</td>\n",
       "      <td>492</td>\n",
       "      <td>30</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NSC2b</td>\n",
       "      <td>80</td>\n",
       "      <td>442</td>\n",
       "      <td>199</td>\n",
       "      <td>222</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Apop.-NSC</td>\n",
       "      <td>34</td>\n",
       "      <td>55</td>\n",
       "      <td>34</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NCSC</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Apop.-NCSC</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Glial-precursors</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Immature-neurons</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bulk_like</td>\n",
       "      <td>88</td>\n",
       "      <td>1445</td>\n",
       "      <td>363</td>\n",
       "      <td>946</td>\n",
       "      <td>50</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Cell Type  Significant TFs  Total Unique Pathways  Reactome  GO_BP  \\\n",
       "0             NSC1a               80                    477       167    282   \n",
       "1             NSC1b               84                    652       215    400   \n",
       "2             NSC2a               85                    848       289    492   \n",
       "3             NSC2b               80                    442       199    222   \n",
       "4         Apop.-NSC               34                     55        34     18   \n",
       "5              NCSC                0                      0         0      0   \n",
       "6        Apop.-NCSC                0                      0         0      0   \n",
       "7  Glial-precursors                0                      0         0      0   \n",
       "8  Immature-neurons                0                      0         0      0   \n",
       "9         bulk_like               88                   1445       363    946   \n",
       "\n",
       "   WP  KEGG  \n",
       "0  15    13  \n",
       "1  16    21  \n",
       "2  30    37  \n",
       "3  10    11  \n",
       "4   1     2  \n",
       "5   0     0  \n",
       "6   0     0  \n",
       "7   0     0  \n",
       "8   0     0  \n",
       "9  50    86  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lib = 'ENCODE_and_ChEA_Consensus_TFs_from_ChIP-X'\n",
    "dbs_to_count = ['Reactome', 'GO_BP', 'WP', 'KEGG']\n",
    "\n",
    "# Create an empty list to store the summary data from each cell type\n",
    "summary_data = []\n",
    "\n",
    "# --- Analysis Loop ---\n",
    "for ct in cell_types:\n",
    "    try:\n",
    "        # Define file paths\n",
    "        tf_file = os.path.join(output_dir, 'gseapy', 'tables', f\"gseapy_{ct}_sig_tf.csv\")\n",
    "        link_file = os.path.join(output_dir, 'gseapy', 'tables', f\"gseapy_{ct}_tf_path_links.csv\")\n",
    "\n",
    "        # Read data\n",
    "        tf = pd.read_csv(tf_file)\n",
    "        link = pd.read_csv(link_file)\n",
    "\n",
    "        # Filter TFs by the specified library\n",
    "        tf_sub = tf[tf['Gene_set'] == lib]\n",
    "        \n",
    "        # Filter pathway links to match the significant TFs\n",
    "        significant_tf_terms = list(tf_sub['Term'])\n",
    "        link_sub = link[link['TF'].isin(significant_tf_terms)]\n",
    "\n",
    "        # --- Pathway Counting ---\n",
    "        num_tfs = len(tf_sub)\n",
    "        \n",
    "        # Base dictionary for the summary row\n",
    "        row = {'Cell Type': ct, 'Significant TFs': num_tfs}\n",
    "\n",
    "        if not link_sub.empty:\n",
    "            # 1. Filter for unique pathways\n",
    "            unique_pathways = link_sub.drop_duplicates(subset=['Pathway_ID'])\n",
    "            \n",
    "            # 2. Get the total count of unique pathways\n",
    "            row['Total Unique Pathways'] = len(unique_pathways)\n",
    "            \n",
    "            # 3. Get the counts per database\n",
    "            db_counts = unique_pathways['Pathway_DB'].value_counts()\n",
    "            \n",
    "            # Add counts for each specified DB, defaulting to 0 if not found\n",
    "            for db in dbs_to_count:\n",
    "                row[db] = db_counts.get(db, 0)\n",
    "        else:\n",
    "            # If no pathways, set all pathway counts to 0\n",
    "            row['Total Unique Pathways'] = 0\n",
    "            for db in dbs_to_count:\n",
    "                row[db] = 0\n",
    "        \n",
    "        # Add the completed summary row to our list\n",
    "        summary_data.append(row)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"⚠️ Warning: Files not found for cell type '{ct}'. Skipping.\")\n",
    "        # Create a row indicating the error\n",
    "        error_row = {'Cell Type': ct, 'Significant TFs': 'File not found'}\n",
    "        error_row.update({db: 'N/A' for db in ['Total Unique Pathways'] + dbs_to_count})\n",
    "        summary_data.append(error_row)\n",
    "\n",
    "# --- Final Table ---\n",
    "# Convert the list of summaries into a single DataFrame\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "# Reorder columns for clarity\n",
    "final_cols = ['Cell Type', 'Significant TFs', 'Total Unique Pathways'] + dbs_to_count\n",
    "summary_df = summary_df[final_cols]\n",
    "\n",
    "# Display the final summary table\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a257920-570f-4e4a-a2e8-413bcc31b8f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7dfa0d-d611-4666-b403-125c5a9296b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
